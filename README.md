# Introduction
**Aperçu :** Ce projet se concentre sur l'application des techniques d'apprentissage supervisé et non supervisé dans le domaine du Data Mining. Il vise à explorer les méthodes de clustering et de classification pour analyser et prédire la fertilité des sols.

**Objectifs :** L'objectif principal est de comprendre et d'appliquer des algorithmes tels que K-means, DBSCAN, KNN et Decision Trees pour le prétraitement et l'analyse des données.

**Portée :** Le rapport couvre l'analyse des données, le choix et l'application des algorithmes, ainsi que l'interprétation des résultats obtenus.

# Technologies utilisées
**Langage de programmation :** Python, pour sa polyvalence et sa riche bibliothèque de Data Science.

**Bibliothèques principales :** sklearn, pour les algorithmes de Machine Learning, et d'autres bibliothèques Python pour le traitement de données.

# Dépendances du code 
**Pandas :** Une bibliothèque de manipulation et d’analyse de données offrant des structures
de données et des opérations pour manipuler des tableaux numériques et des séries temporelles.
Pandas est utilisé pour le chargement et le prétraitement des données avant l’application des
techniques de clustering.

**NumPy :** Fondamental pour les calculs scientifiques en Python, NumPy offre un support
pour des tableaux multidimensionnels et des matrices, ainsi que des fonctions mathématiques
de haut niveau pour opérer sur ces structures de données.

**Scikit-learn :** Une bibliothèque puissante pour l’apprentissage automatique en Python,
qui fournit des implémentations simples et efficaces de nombreux algorithmes de clustering, y
compris K-means et DBSCAN, ainsi que des outils pour le calcul des métriques de performance.

**Matplotlib et Seaborn :** Ces bibliothèques de visualisation sont utilisées pour générer
des graphiques en barres, des heatmaps et d’autres types de visualisations pour analyser les
résultats de clustering et les métriques associées.

**Jupyter Notebook :** L’environnement de développement interactif utilisé pour la création
de notre code. Il permet une intégration transparente du code, des commentaires et des visualisations.

**Streamlit :** Utilisé pour la création d’interfaces utilisateur interactives, Streamlit permet
de transformer rapidement des scripts de data science en applications web partageables.
NB : On utilisé la commande "streamlit run .\interface.py" pour lancer l’interface.

# Contributeurs
**Auteurs :** Ce projet a été réalisé par **Aymen Benkouiten** et **Tarek Noughi**, sous la supervision de **Mme Belkadi Widad Hassina**, dans le cadre d'un travail universitaire à l'Université des Sciences et de la Technologie Houari Boumediene.
